# üìä DataQuery-IA

Um sistema web que permite a an√°lise de dados de tabelas de produtos em tempo real usando Intelig√™ncia Artificial local, garantindo privacidade e processamento eficiente atrav√©s do Ollama.

O objetivo do projeto √© demonstrar a integra√ß√£o de um frontend moderno (SvelteKit + Tailwind CSS) com um modelo de Linguagem Grande (LLM) rodando localmente (Llama 2 ou Mistral).

---

## ‚ú® Tecnologias Utilizadas

- **Frontend**: [SvelteKit](https://kit.svelte.dev/)
- **Estiliza√ß√£o**: [Tailwind CSS](https://tailwindcss.com/)
- **UI Componentes**: [shadcn-svelte](https://www.shadcn-svelte.com/)
- **Backend & API**: SvelteKit Endpoints (`+server.ts`)
- **Intelig√™ncia Artificial**: [Ollama](https://ollama.com/) (Servidor Local de LLMs)
- **Modelo de IA**: [Mistral](https://mistral.ai/)
- **Linguagens**: TypeScript, HTML, CSS
---

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

Siga os passos abaixo para configurar e rodar o projeto em sua m√°quina Ubuntu (ou outro sistema operacional compat√≠vel).

### 1. Pr√©-requisitos

Certifique-se de ter instalado:
- **Node.js e npm**: Para o projeto SvelteKit.
- **Ollama**: Para rodar a IA localmente.

### 2. Configura√ß√£o do Projeto Web (SvelteKit)

Clone o reposit√≥rio e instale as depend√™ncias:
```bash
git clone https://github.com/rogeriosaraceni/dataQuery-ia
cd dataQuery-ia
npm install
```

### 3. Configura√ß√£o do Ollama (IA Local)

Voc√™ precisa garantir que o servi√ßo Ollama esteja rodando e que o modelo necess√°rio esteja baixado.

**A. Instalar o Ollama (se ainda n√£o fez):**

Siga as instru√ß√µes oficiais em ollama.com.

**B. Baixar o Modelo de IA:**

Abra um terminal e baixe o modelo que o projeto utiliza (`llama2`):
```bash
ollama pull llama2
# Alternativamente, voc√™ pode usar 'mistral' para um modelo mais r√°pido:
# ollama pull mistral
```

**C. Verificar e Iniciar o Servi√ßo (Ubuntu/Linux):**

Confirme se o servi√ßo est√° ativo (geralmente inicia automaticamente):
```bash
# Verifique o status do servi√ßo:
sudo systemctl status ollama

# Se n√£o estiver rodando, inicie:
sudo systemctl start ollama

# Para parar o servi√ßo
sudo systemctl stop ollama
```

### 4. Rodando o Projeto

Com o Ollama rodando em um terminal separado (ou em segundo plano via servi√ßo), inicie o servidor de desenvolvimento do SvelteKit:
```bash
npm run dev
```

Abra seu navegador e visite http://localhost:5173 (ou a porta indicada pelo Vite).

---

## üöÄ Uso

1. Na p√°gina inicial, voc√™ ver√° uma tabela de produtos estilizada com Tailwind CSS.
2. Abaixo da tabela, h√° um campo de texto (`<textarea>`) onde voc√™ pode digitar perguntas sobre os dados da tabela.
3. Clique em **"Analisar com IA Local"**.
4. O frontend far√° uma requisi√ß√£o ao endpoint do SvelteKit, que se comunica com seu servi√ßo Ollama local, e a resposta da IA ser√° exibida na tela.

---

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests no reposit√≥rio para melhorias na estiliza√ß√£o, na engenharia de prompt ou na integra√ß√£o.

---

## üîó Refer√™ncias

- **SvelteKit**: https://kit.svelte.dev/
- **Tailwind CSS**: https://tailwindcss.com/
- **Ollama**: https://ollama.com/
- **Mistral AI**: https://mistral.ai/
